"""
Unit 05 Project: Web Service APIs - Data Aquisition Notebook
John Fernow, Jordan Gelber  
12 December 2017
"""
import requests, json, keys
import pandas as pd
#===========================================================
def getAccessToken():
    """
    This function connects takes information created from our Yelp 
    keychain and posts it to the corresponding URL in order to
    receive an access token. 
    
    Input: None
    Output: string access_token 
    """
    # gather information from keys.py
    keychain = keys.keychain
    client_id = keychain['yelp']['client_id']
    client_secret = keychain['yelp']['client_secret']
    
    # request token 
    r = requests.post('https://api.yelp.com/oauth2/token?grant_type=client_credentials&client_id='+client_id+'&client_secret='+client_secret)
    
    # save response as dictionary
    r_dict = json.loads(r.text)

    # save token from response body 
    access_token = r_dict['access_token']
    
    return access_token
getAccessToken()
#===========================================================
def getBusinessInfo(location):
    """Function returns a Pandas Dataframe for 50 businesses in the 
    given location. It does so by running a function that gathers
    the data, and then a function that converts that data to a 
    dataframe. Before converting to dataframe, it verifies that
    the data could successfully be gathered from Yelp's servers, and
    has back up steps in the case it fails, such as requesting a new
    token and offering the user the ability to wait if the API limit
    has been exceeded.
    
    Input: location
    Output: Pandas Dataframe
    """
    def getData():
        """Gathers data on 50 businesses in that location
        Input: None
        Output: 6 lists on data for that location
        """
        # construct URL
        url = 'https://api.yelp.com/v3/businesses/search' # base
        headers = {'Authorization': 'bearer %s' % access_token} # authorize
        params = {'location':location, 'limit':'50', 'sort_by':'distance'} # queries

        # get response body
        response = requests.get(url, headers=headers, params=params)

        # convert response to dictionary
        body = json.loads(response.text)

        # create list of business IDs
        ids, ratings, reviewCount, prices, transactions, categories = [],[],[],[],[],[]
        for i in range(50): # 49 because limit is set to 50
            ids.append(body['businesses'][i]['id'])
            ratings.append(body['businesses'][i]['rating'])
            reviewCount.append(body['businesses'][i]['review_count'])
            transactions.append(body['businesses'][i]['transactions'])
            categories.append(body['businesses'][i]['categories'])

            try: # for whatever reason, sometimes 'price' is missing
                prices.append(body['businesses'][i]['price'])
            except:
                prices.append('')            

        return ids, ratings, reviewCount, prices, transactions, categories 

    
    try:
        # attempts to run function with current token
        ids, ratings, reviewCount, prices, transactions, categories = getData()
    except:
        try:
            # gets new access token incase it expired
            access_token = getAccessToken()
            ids, ratings, reviewCount, prices, transactions, categories = getData()
        except:
            # allows time to elapse if passed the API limit 
            print("You have passed the daily API limit (25,000 calls).")
            print("The program will resume 24 hours from now.")
            print("Current time: ")
            import time, datetime
            print(datetime.datetime.now())
            print("Would you like to continue and wait? Y/N")
            answer = input()
            if answer.upper() == 'Y':
                time.sleep(86400)
                try:
                    ids, ratings, reviewCount, prices, transactions, categories = getData()
                except:
                    print("Critical error. Either application has been terminated by Yelp or the API format has changed.")
            else:
                print("Ending program.")
                exit() #kills kernel so it doesn't run other functions
                
    def createDF():
        """Creates Panda Dataframe from lists generated by getData().
        Input: None
        Output: Pandas Dataframe
        """
        d = {'Business ID':ids, 'Rating':ratings,
             'Review Count':reviewCount,'Price Range':prices,
             'Transactions Available':transactions,
             'Categories':categories}
        df = pd.DataFrame(d)
        return df
    
    return(createDF())
#===========================================================
# This runs our search query for the top 20 most populated 
# cities in United States. 

locations = ['New+York,New+York','Los+Angeles,California',
             'Chicago,Illinois', 'Houston,Texas',
             'Phoenix,Arizona', 'Philadelphia,Pennsylvania',
             'San+Antonio,Texas', 'San+Diego,California',
             'Dallas,Texas','San+Jose,California', 'Austin,Texas',
             'Jacksonville,Florida', 'San+Francisco,California',
             'Columbus,Ohio', 'Indianapolis,Indiana',
             'Fort+Worth,Texas', 'Charlotte,North+Carolina',
             'Seattle,Washington', 'Denver,Colarado',
             'El+Paso,Texas']

dfDict = {} # dictionary of dataframes for all above locations

# runs search query for every single city in that list
for city in locations:
    dfDict[city] = getBusinessInfo(city)
#===========================================================
def exportToCSV():
    """Takes all of the Dataframes and exports them to a CSV files.
    It also creates a DataFrame of the data from all of the cities
    combined and exports that as a master CSV file. 
    
    Input: None
    Output: None (though exports CSV files)"""
    
    dfLists = []
    # generate individual CSVs
    for i in range(len(locations)):
        dfDict[locations[i]].to_csv(locations[i]+'.csv')
        dfLists.append(dfDict[locations[i]])
        
    # create DF of all cities
    masterDF = pd.concat(dfLists)
    masterDF.to_csv('master.csv',index=False)
#===========================================================
exportToCSV()
